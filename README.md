Hi, I'm Mark ğŸ‘‹

  System Workflow Architect â€¢ Associate Data Engineer â€¢ Solutions Builder  



ğŸ§  About Me
I'm a backend-first engineer passionate about crafting explicit, maintainable, and production-grade systems. My expertise lies in building state-aware workflows, real-time data pipelines, and operationally safe platforms that eliminate silent failures and ensure reliability. I approach every project with a focus on auditability, reproducibility, and future-proof design, ensuring systems are robust and adaptable to evolving requirements.
I specialize in creating cost-efficient, scalable solutions that balance performance, budget, and resource constraints. From designing trigger-based job order systems to streaming Kafka pipelines for real-time analytics, I anticipate edge cases and prioritize operational clarity. My deployments span platforms like Heroku, Vercel, Render, and Hostinger, always optimized for sustainability and practicality.

ğŸ› ï¸ Tech Stack & Tools
ğŸ’» Languages & Frontend




âš™ï¸ Frameworks & APIs




ğŸ—„ï¸ Databases




ğŸš€ Deployment Platforms




ğŸ§  Data Engineering & Caching




ğŸ›¡ï¸ DevOps & Tools





ğŸ“ Certifications

ğŸ§ª Associate Data Engineer (DataCamp)Certified in designing scalable data pipelines, secure storage systems, and real-time analytics workflows. Demonstrated expertise in data modeling, ETL processes, and performance optimization.

ğŸ“Š Data Engineering with Python (DataCamp)Mastered Python-based data engineering tools, including Pandas, PySpark, and Airflow, for building robust data pipelines and analytics systems.



ğŸ’¼ Experience & Mindset

Architected state-aware backend workflows with explicit transition logic to ensure operational safety and prevent silent failures.
Developed real-time data ingestion pipelines using Kafka, PySpark, and dashboard integrations for low-latency analytics.
Refactored complex PL/pgSQL stored procedures to handle edge cases, recursion, and schema evolution while maintaining performance.
Automated metrics population and reporting with conflict-safe upserts, deduplication logic, and scheduled tasks using pg_cron.
Designed systems with auditability, reproducibility, and operational clarity as core principles, ensuring transparency and reliability.
Optimized deployments for cost-efficiency across platforms like Heroku, Vercel, and AWS, balancing performance with budget constraints.

My mindset is rooted in pragmatic problem-solvingâ€”I build systems that are not only technically sound but also aligned with business goals and resource realities. I prioritize data security, privacy, and sustainability, ensuring every solution is robust, scalable, and maintainable.

ğŸš€ Featured Projects
ğŸ”„ Real-Time Billing Recalculation

Engineered a PL/pgSQL-based recalculation engine using triggers and transactional logic to enforce minimum charge rules and consumption thresholds.
Integrated with pg_cron for automated CSV exports and reporting.
Ensured auditability with detailed transaction logs and rollback mechanisms.
Deployed on Heroku with optimized resource allocation.

ğŸ§¾ State-Aware Job Order Workflow

Designed a PostgreSQL trigger-based workflow with explicit state transition logic to prevent unsafe edits and silent failures.
Built for scalability and future-proofed against schema changes and evolving business rules.
Deployed on Render with automated backups and monitoring.

ğŸ“Š Kafka â†’ PySpark â†’ Dashboard

Developed a real-time data ingestion pipeline using Kafka for streaming, PySpark for data cleaning, and dashboard integrations for operational insights.
Optimized for low-latency feedback loops and high-throughput processing.
Deployed on AWS with Docker containers for scalability.

ğŸ“ˆ Metrics Automation Engine

Built a metrics automation system using PL/pgSQL stored procedures for monthly data population.
Implemented conflict-safe upserts and deduplication logic to ensure data integrity.
Scheduled tasks with pg_cron and deployed on Heroku with automated monitoring.

ğŸ§  What I Care About

Database Design: Building clear, scalable, and secure schemas that support long-term growth.
Data Security & Privacy: Embedding encryption, access controls, and compliance at every layer.
Operational Reliability: Ensuring systems are auditable, reproducible, and resilient to failures.
Eco-Friendly Digital Solutions: Reducing reliance on paper-based processes and optimizing resource usage.
Practical Development Design: Delivering solutions that respect cost, performance, and deployment constraints.


ğŸ“« Letâ€™s Connect

LinkedIn: [linkedin.com/in/yourprofile](https://www.linkedin.com/in/mj-almojuela/)
Email: mjalmojuela.dasher@gmail.com



â€œI donâ€™t just build systems â€” I build systems that yield value, scale gracefully, and stand the test of time.â€â€” Mark
